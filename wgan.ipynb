{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wgan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9WRX4RIJsJNE"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TW3siaExWAF8"
      },
      "source": [
        "# WGAN\n",
        "論文：[Wasserstein GAN](https://arxiv.org/abs/1701.07875)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uJPsgRAsWAF9"
      },
      "source": [
        "## WGANとは\n",
        "真のデータ分布とGeneratorによる生成データの分布の距離の計算に，Wasserstein距離を用いるGAN．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NNgDWkSxWAF-"
      },
      "source": [
        "## GANの問題点\n",
        "\n",
        "既存のGANにおける学習はJensen-Shannonダイバージェンス(JSD)を最小化することで，生成データを真のデータに似せていた．\n",
        "\n",
        "しかし，JSDに基づく学習では，以下のような問題点がある．\n",
        "\n",
        "- 学習が不安定\n",
        "\n",
        "    - 真の分布とモデルの分布が重ならない場合では勾配消失問題が発生する\n",
        "    \n",
        "    - GeneratorとDiscriminatorとの学習バランスの設定が難しい（主にDiscriminatorが強くなりすぎる）\n",
        "\n",
        "- モード崩壊が起こる\n",
        "\n",
        "- 生成データのクオリティ（学習の進み具合）が損失関数の値から判断しずらい "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YD_7uPmAWAF_"
      },
      "source": [
        "## WGANの改良点\n",
        "- 学習が安定しなかった問題を解決\n",
        "\n",
        "    - Wasserstein距離を用いることにより，真の分布とモデルの分布が重ならない場合でも微分可能に（勾配消失が起こらない）\n",
        "    \n",
        "    - 勾配が得られ続けるので，GeneratorとDiscriminatorのシビアな学習バランス設定がいらない\n",
        "\n",
        "- モード崩壊を解消\n",
        "\n",
        "- Wasserstein距離 $\\approx$ 生成データの品質 なので学習の進み具合がわかりやすい"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6wPRnTiTWAGA"
      },
      "source": [
        "## Wasserstein距離\n",
        "\n",
        "先述のように，従来のJSDを用いたGANにおける問題点の１つに「真の分布とモデルの分布が重ならない場合では勾配消失問題が発生する」というものがあった．\n",
        "\n",
        "GANでの学習の目的は，真の分布$P_{data}$とモデルの分布$P_{g}$との確率分布を一致させることであるが，重ならない場合ではJSDが定義できない．\n",
        "\n",
        "例えば，確率分布が重ならない極端な例の場合について，JSDを計算する．\n",
        "\n",
        "<img src=\"https://i.imgur.com/R6s5JOe.png\" width=\"60%\">\n",
        "\n",
        "$$\n",
        "\\large\n",
        "\\begin{align}\n",
        "    \\tag{1}\n",
        "    &D_{JS}(P_{data}\\| P_g)=\\frac{1}{2}D_{KL}\\Bigl(P_{data}\\|\\frac{P_{data}+P_g}{2}\\Bigr)+\\frac{1}{2}D_{KL}\\Bigl(P_g\\mid\\mid\\frac{P_{data}+P_g}{2}\\Bigr)\\\\\n",
        "    =&\n",
        "    \\begin{cases}\n",
        "        \\frac{1}{2}\\Bigl(\\sum_{}^{}1\\times {\\rm log}\\bigl(\\frac{1}{1/2}\\bigr)+\\sum_{}^{}1\\times {\\rm log}\\bigl(\\frac{1}{1/2}\\bigr)\\Bigr)\\quad(\\theta\\neq 0)\\\\\n",
        "        0\\quad(\\theta = 0)\n",
        "    \\end{cases}\n",
        "    \\\\\n",
        "    =&\n",
        "    \\begin{cases}\n",
        "        log(2)\\quad(\\theta\\neq 0)\\\\\n",
        "        0\\quad(\\theta =0)\n",
        "    \\end{cases}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "これをグラフにすると以下のようになる．(論文より引用)\n",
        "\n",
        "真の分布とモデルの分布が重なる$\\theta = 0$の部分でJSDが0になるので不連続となっており，勾配消失していることがわかる．\n",
        "\n",
        "<img src=\"https://imgur.com/zGuRVOl.png\" width=\"50%\">\n",
        "\n",
        "\n",
        "WGANではこの勾配消失問題を回避するために，以下の式で定義されるWasserstein距離を使用する．\n",
        "\n",
        "ここでinfは下限のことであり，厳密には異なるらしいが最小値と同じと捉えてもいいだろう．\n",
        "\n",
        "$$\n",
        "\\large\n",
        "\\begin{align}\n",
        "    \\tag{2}\n",
        "    W\\bigl(P_{data}(x)\\| P_g(x)\\bigr) &= \\underset{\\gamma\\in\\Pi}{\\rm inf}\\sum_{x,y}^{}\\| x-y\\|\\:\\gamma(x,y)\\\\\n",
        "    &=\\underset{\\gamma\\in\\Pi}{\\rm inf}\\;\\mathbb{E}_{(x,y)\\sim\\gamma}\\| x-y\\|\n",
        "\\end{align}\n",
        "$$\n",
        "$$\n",
        "\\begin{align}\n",
        "\\cdot\\;&\\gamma(x,y)\\in\\Pi(P_{data},P_g)\\\\\n",
        "\\cdot\\;&\\displaystyle\\sum_{x}^{}\\gamma (x,y)=P_{data}(y) , \\displaystyle\\sum_{y}^{}\\gamma(x,y)=P_{data}(x)\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "このWasserstein距離を先ほど(確率分布が重ならない場合)と同様に計算すると\n",
        "$$W\\bigl(P_{data}\\|P_g\\bigr)=|\\theta |$$\n",
        "\n",
        "となり，これをグラフにすると以下のようになる．(論文より引用)\n",
        "\n",
        "<img src=\"https://imgur.com/C3DK3sB.png\" width=\"50%\">\n",
        "\n",
        "グラフからわかるように，勾配が連続しており，勾配消失を防ぐことができる．"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 損失関数\n",
        "\n",
        "Wasserstein距離を式(2)に示したが，これは最適輸送問題と同等であり，線形計画法(LP,Linear Programming)を用いることで解くことができる．\n",
        "\n",
        "しかし，この手法はGANで扱う画像のように次元が大きい場合では，計算量が非現実的になってしまうので双対表現の式を用いる．\n",
        "\n",
        "双対表現は最小化問題を最大化問題に変形するもので，証明にはFarkasの補題というものを用いるらしい．\n",
        "\n",
        "双対表現の式は以下で表される．\n",
        "\n",
        "$$\n",
        "\\large\n",
        "\\begin{align}\n",
        "    \\tag{3}\n",
        "    W\\bigl(P_{data}(x)\\| P_g(x)\\bigr) &= \\frac{1}{K}\\underset{\\| f\\|_{L<K}}{\\rm sup}\\mathbb{E}_{x\\sim P_{data}}\\bigl[f(x)\\bigr]-\\mathbb{E}_{x\\sim P_g}\\bigl[f(x)\\bigr]\n",
        "\\end{align}\n",
        "$$\n",
        "$$\n",
        "\\begin{align}\n",
        "\\cdot\\;&f:K{\\rm -}リプシッツ連続な関数\\\\\n",
        "\\cdot\\;&K:リプシッツ定数\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "ここでsupは上限を表す．すごくざっくりな理解では，最小化問題→最大化問題へ変化したということ．\n",
        "\n",
        "また，関数$f$は$K$-リプシッツ連続な関数であることが，元のWasserstein距離の制約条件から必要となる．\n",
        "\n",
        "さらに，識別器(critic)の重みパラメータをwとし，criticの出力を$f_w$と表記すると，双対表現の式(3)は以下の式で近似できる．\n",
        "\n",
        "$$\n",
        "\\large\n",
        "\\begin{align}\n",
        "    \\tag{4}\n",
        "    L_{critic}=W\\bigl(P_{data}(x)\\| P_g(x)\\bigr) &= \\frac{1}{K}\\underset{w\\in W}{\\rm max}\\;\\mathbb{E}_{x\\sim P_{data}}\\bigl[f(x)\\bigr]-\\mathbb{E}_{x\\sim P_g}\\bigl[f(x)\\bigr]\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "WGANでは式(4)の近似式をcriticの損失関数として採用する．\n",
        "\n",
        "（詳しい内容は[参考リンク](#参考リンク)がおすすめ）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qTNCqxt7WAGB"
      },
      "source": [
        "## 実装に使うテクニック\n",
        "\n",
        "- Discriminatorの出力に活性化関数を使わない\n",
        "\n",
        "- OptimizerはRMSPropを用いる\n",
        "  - 学習率を低めに設定\n",
        "\n",
        "- Discriminatorのパラメータを小さな値でクリップする\n",
        "\n",
        "- DiscriminatorのパラメータをGeneratorより多く更新する（Unrolled-GANによるもの？）\n",
        "\n",
        "- **論文で出てくる難しい式は使わない**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jpYZQ_IdWAGC"
      },
      "source": [
        "# 実装\n",
        "PyTorch公式実装(DCGAN)を参考にしました（ほぼ同じ）\n",
        "\n",
        "Google Colabなどでも実行可能ですが，学習にかなり時間がかかるので参考までに..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tj4Xc33TWAGD"
      },
      "source": [
        "まずライブラリやパッケージをimportする．\n",
        "\n",
        "また，Generatorに入力するノイズベクトルのシードを決定する（ここでは再現性のために999に指定）．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "m74s-e8JWAGE"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iFLLkYCzWAGG"
      },
      "source": [
        "## パラメータ設定\n",
        "実行のための各パラメータを定義：\n",
        "\n",
        "* **dataroot** - データセットフォルダへのパス\n",
        "\n",
        "* **workers** - いくつのコアでデータをロードするか\n",
        "\n",
        "* **batch_size** - バッチサイズ\n",
        "\n",
        "* **image_size** - 学習用画像のサイズ（画像のサイズを変更するにはネットワーク構造を要変更）\n",
        "\n",
        "* **nc** - 入力画像のカラーチャンネル\n",
        "\n",
        "* **nz** - Generatorに入力するノイズベクトルの次元数\n",
        "\n",
        "* **ngf** - 伝搬される特徴マップの深さ（Generator用）\n",
        "\n",
        "* **ndf** - 伝搬される特徴マップの深さ（Discriminator用）\n",
        "\n",
        "* **num_epochs** - エポック数\n",
        "\n",
        "* **lr** - 学習率（DCGANでは0.0002だが，WGANでは0.00005という小さい値に設定）\n",
        "\n",
        "* **clamp-lower** - Discriminatorのパラメータをクリップするときの下限\n",
        "\n",
        "* **clamp_upper** - 上限\n",
        "\n",
        "* **n_critic** - Gのパラメータを１回更新する毎に，Discriminatorのパラメータを [n_critic回]更新\n",
        "\n",
        "* **ngpu** - GPUの使用枚数（0を指定するとCPUで実行）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lIaQTf3-WAGI"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = \"/dataset/\"\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 128\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 20\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.00005\n",
        "\n",
        "# Lower for clipping parameter of Critic(Discriminator)\n",
        "clamp_lower = -0.01\n",
        "# Upper for clipping parameter of Critic(Discriminator)\n",
        "clamp_upper = 0.01\n",
        "\n",
        "# number of D iters per each G iter\n",
        "n_critic = 5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7sASZGI6WAGL"
      },
      "source": [
        "## データセット\n",
        "datasetとdataloaderを作成．ここでは[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)を用いる．一番下のコードブロックではデータセットの一部を表示している．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "UZVbKlO-WAGN"
      },
      "outputs": [],
      "source": [
        "# Create the dataset\n",
        "dataset = dset.CIFAR10(root=dataroot,\n",
        "                        download=True,\n",
        "                        train=True,\n",
        "                        transform=transforms.Compose([\n",
        "                            transforms.Resize(image_size),\n",
        "                            transforms.CenterCrop(image_size),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                           ]))\n",
        "# Create the dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)\n",
        "\n",
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "as_UZ-XYJBtJ"
      },
      "source": [
        "## ネットワーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CfOrJp4oWAGQ"
      },
      "source": [
        "### Generator\n",
        "Generatorを定義する．WGANではロスにWasserstein距離を使うだけなので，GeneratorはDCGANのネットワークと同じ．\n",
        "\n",
        "Generatorは100次元のノイズベクトルから(128batch, 3ch, 64, 64)のテンソルを生成する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GdjfNp2RWAGR"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*8) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 32 x 32\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. (nc) x 64 x 64\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mw-1eF8kWAGU"
      },
      "outputs": [],
      "source": [
        "# Create the generator\n",
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Print the model\n",
        "print(netG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iwGNXL8XWAGX"
      },
      "source": [
        "### Discriminator\n",
        "DCGANではGeneratorからの出力を受け取り，Sigmoid関数によって最終確率を出力していた．\n",
        "\n",
        "WGANはその必要がない．Discriminatorの出力の平均をWasserstein距離の計算に使うので，最終層の活性化関数は不要．\n",
        "\n",
        "したがってDCGANのSigmoid関数のみを取り除いた構造になり，いたってシンプル．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cch70NQGWAGa"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 64 x 64\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 32 x 32\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 16 x 16\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 8 x 8\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*8) x 4 x 4\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "isEF_p9qWAGd"
      },
      "outputs": [],
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-gpu if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Print the model\n",
        "print(netD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ny-aJH03WAGh"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "最適化アルゴリズムにはRMSPropを採用している．Adamでは学習が不安定になることがあり，RMSPropを使うと改善されたと書かれている：\n",
        ">We therefore switched to RMSProp which is known to perform well even on very nonstationary problems.\n",
        "\n",
        "また，学習率は0.00005という低い学習率を設定する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GTDKMm1hWAGi"
      },
      "outputs": [],
      "source": [
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.RMSprop(netD.parameters(), lr=lr)\n",
        "optimizerG = optim.RMSprop(netG.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7nZiDNLhWAGl"
      },
      "source": [
        "## 学習\n",
        "ロス関数の実装には論文に記載されている式は一切使わない．\n",
        "\n",
        "本物データに対するDiscriminatorの出力の平均を$f_w(x)$，Generatorによる偽データに対するDの出力の平均を$f_w(\\hat{x})$とする．\n",
        "\n",
        "また，Discriminatorのパラメータを$w$，Generatorのパラメータを$\\theta$とする．\n",
        "\n",
        "学習のステップは以下の通り：\n",
        "\n",
        "1. $w$を$f_w(x) - f_w(\\hat{x})$で更新\n",
        "\n",
        "2. $w$を$[-c,c]$の範囲でクリップ\n",
        "\n",
        "3. 1と2を$n_{critic}$回繰り返す\n",
        "\n",
        "4. $\\theta$を$f_w(\\hat{x})$で更新\n",
        "\n",
        "$f_w(x) - f_w(\\hat{x})$がWasserstein距離を表している．\n",
        "\n",
        "Discriminatorは本物のデータに対し大きな値を出力し、偽のデータに対して小さな値を出力する必要がある．したがって，$f_w(x) - f_w(\\hat{x})$を最大化する．\n",
        "\n",
        "$w$を更新する毎に$[-c,c]$でクリップするのは，リプシッツ制約を保つためである．\n",
        "\n",
        "Generatorは$f_w(\\hat{x})$を最大化することで，Wasserstein距離($f_w(x) - f_w(\\hat{x})$)を小さくする．(つまり真の分布とモデルの分布を近づける)\n",
        "\n",
        "1と4のステップでは目的関数を最大化すると記述したが，**PyTorchではロス関数として最小化されるので，目的関数にマイナスをかける．**\n",
        "\n",
        "したがって，GeneratorとDiscriminatorのロス関数は以下のようになる：\n",
        "- D： $-f_w(x) + f_w(\\hat{x})$\n",
        "- G： $-f_w(\\hat{x})$\n",
        "\n",
        "コードは以下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "itrUlUVOWAGm"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        \n",
        "        #############################\n",
        "        # 3. Repeat [n_critic] times\n",
        "        #############################\n",
        "        for n in range(n_critic):\n",
        "\n",
        "            ############################\n",
        "            # 1. Update D network\n",
        "            ###########################\n",
        "            ## Train with all-real batch\n",
        "            netD.zero_grad()\n",
        "            # Format batch\n",
        "            real_cpu = data[0].to(device)\n",
        "            b_size = real_cpu.size(0)\n",
        "            # Forward pass real batch through D\n",
        "            output = netD(real_cpu).view(-1)\n",
        "            # Calculate loss on all-real batch\n",
        "            errD_real = torch.mean(output)\n",
        "            # Calculate gradients for D in backward pass\n",
        "            D_x = output.mean().item()\n",
        "\n",
        "            ## Train with all-fake batch\n",
        "            # Generate batch of latent vectors\n",
        "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "            # Generate fake image batch with G\n",
        "            fake = netG(noise)\n",
        "            # Classify all fake batch with D\n",
        "            output = netD(fake.detach()).view(-1)\n",
        "            # Calculate D's loss on the all-fake batch\n",
        "            errD_fake = torch.mean(output)\n",
        "            # Calculate the gradients for this batch\n",
        "            D_G_z1 = output.mean().item()\n",
        "            # Add the gradients from the all-real and all-fake batches\n",
        "            errD = - errD_real + errD_fake\n",
        "            errD.backward()\n",
        "            # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "            ##################################\n",
        "            # 2. Clip weights of discriminator\n",
        "            ##################################\n",
        "            for p in netD.parameters():\n",
        "                p.data.clamp_(clamp_lower, clamp_upper)\n",
        "\n",
        "        ############################\n",
        "        # 4. Update G network\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = - torch.mean(output)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "        \n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch+1, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        \n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "        \n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "            \n",
        "        iters += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jTlh_-L9FkCm"
      },
      "source": [
        "## 結果の表示\n",
        "\n",
        "※学習に時間がかかる．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LMx1iPVSWAGp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "WQaPLsDbWAGw"
      },
      "outputs": [],
      "source": [
        "#%%capture\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3aB6TDeUWAG0"
      },
      "outputs": [],
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "btMmTFH1IkO5"
      },
      "source": [
        "# ポケモン生成してみた\n",
        "\n",
        "## 生成結果\n",
        "\n",
        "左が通常のGANの目的関数，右がWasserstein距離を用いたWGAN．ネットワークはどちらもDCGANのものを使用している．\n",
        "\n",
        "DCGANの方が早く収束するようだが，学習が不安定でmode collapseを起こしている．\n",
        "\n",
        "それに対しWGANは学習に時間を要するが安定しており，より鮮明に生成された．\n",
        "\n",
        "|DCGAN|WGAN|\n",
        "|:---:|:---:|\n",
        "|<img src=\"https://i.imgur.com/7oHacMp.gif\" width=80%>|<img src=\"https://i.imgur.com/S9cHDtV.gif\" width=80%>|\n",
        "\n",
        "\n",
        "## 学習曲線\n",
        "\n",
        "WGANのDiscriminatorのロス(Wasserstein距離) $\\approx$ 生成画像のクオリティー なので学習の進捗がわかりやすい．\n",
        "\n",
        "DCGANは学習が不安定になっており，Discriminatorが強くなってしまった．\n",
        "\n",
        "**※Discriminatorのロスが増加しているように見えるが，ロス自体がWasserstein距離を表しているので，0に向かうように収束する．**\n",
        "- Discriminator\n",
        "\n",
        "|DCGAN|WGAN|\n",
        "|:---:|:---:|\n",
        "|<img src=\"https://i.imgur.com/cdS6w4T.png\">|<img src=\"https://i.imgur.com/6yhzsH9.png\">|\n",
        "\n",
        "- Generator\n",
        "\n",
        "|DCGAN|WGAN|\n",
        "|:---:|:---:|\n",
        "|<img src=\"https://i.imgur.com/3uzNZgw.png\">|<img src=\"https://i.imgur.com/ZJN9iiB.png\">|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1V-ODf7DTKWZ"
      },
      "source": [
        "# 気づいたこと\n",
        "\n",
        "- 学習回数（エポック数）は多めに設定\n",
        "\n",
        "  - 学習率を低く設定している，つまり学習が遅いのでエポック数は多めに設定\n",
        "\n",
        "- 通常のGANより時間がかかる\n",
        "\n",
        "- ロス(Wasserstein距離)の推移は見た方がいい\n",
        "\n",
        "- 論文ではDiscriminatorに正規化は不要と書かれているが，ポケモン生成ではBatch Normalizationをなくすと結果が悪化した(データセットによるのかも？)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p2izp3t5W11E"
      },
      "source": [
        "# 参考リンク\n",
        "\n",
        "- 理論\n",
        "  - [GANからWasserstein GANへ](https://daiki-yosky.hatenablog.com/entry/2019/04/24/GAN%E3%81%8B%E3%82%89Wasserstein_GAN%E3%81%B8)\n",
        "  \n",
        "  - [Wasserstein GAN [arXiv:1701.07875] ご注文は機械学習ですか？](http://musyoku.github.io/2017/02/06/Wasserstein-GAN/)\n",
        "\n",
        "  - [Wasserstein GAN と Kantorovich-Rubinstein 双対性](https://qiita.com/mittyantest/items/0fdc9ce7624dbd2ee134)\n",
        "\n",
        "  - [今さら聞けないGAN（4） WGAN](https://qiita.com/triwave33/items/5c95db572b0e4d0df4f0)\n",
        "\n",
        "  - [情報工学_機械学習_生成モデル.md](https://github.com/Yagami360/My_NoteBook/blob/master/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6/%E6%83%85%E5%A0%B1%E5%B7%A5%E5%AD%A6_%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92_%E7%94%9F%E6%88%90%E3%83%A2%E3%83%87%E3%83%AB.md#WGAN)\n",
        "\n",
        "- 実装\n",
        "\n",
        "   - [論文著者のリポジトリ](https://github.com/martinarjovsky/WassersteinGAN)\n",
        "\n",
        "   - [GAN_WGAN_PyTorch](https://github.com/Yagami360/MachineLearning_Exercises_Python_PyTorch/tree/master/GAN_WGAN_PyTorch)"
      ]
    }
  ]
}