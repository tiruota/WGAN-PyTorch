{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/tiruota/WGAN-PyTorch/blob/master/train_gaussian_mixture/wgan_gaussian_mixture.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN Gaussian Mixture\n",
    "\n",
    "GANの問題点の一つだった\"mode collapse\"をWGANでは回避できることを確認するnotebook"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## どうやって確認するのか\n",
    "\n",
    "平均をずらした正規分布の混合分布を真のデータに用いる．\n",
    "\n",
    "入力ノイズzをGeneratorに入力し，出力の分布が真の分布を捉えることができるか，というもの．"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 分布の生成・プロット\n",
    "\n",
    "関数\"gaussian_mixture_circle\"は単円状，\"gaussian_mixture_double_circle\"は二重円状の混合分布を生成する．\n",
    "\n",
    "また以下のように，生成した分布を\"plot_scatter\"でプロットし，\"plot_kde\"で分布のカーネル密度推定を描画する．\n",
    "\n",
    "- gaussian_mixture_circle\n",
    "\n",
    "|scatter|KDE|\n",
    "|:---:|:---:|\n",
    "|![scattar_true](https://imgur.com/6NbbeMi.png)|![kde_true](https://imgur.com/b6AypjF.png)|\n",
    "\n",
    "- gaussian_mixture_double_circle\n",
    "\n",
    "|scatter|KDE|\n",
    "|:---:|:---:|\n",
    "|![scattar_true](https://imgur.com/jKl2QjV.png)|![kde_true](https://imgur.com/HX4oSGM.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## パラメータ設定\n",
    "\n",
    "- **num_mixture** - 正規分布の個数\n",
    "\n",
    "- **scale** - 混合正規分布が成す円の大きさ\n",
    "\n",
    "- **std** - 正規分布の標準偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mixture = 8\n",
    "scale = 2.0\n",
    "std = 0.2\n",
    "batchSize = 100\n",
    "nc = 2\n",
    "nz = 256\n",
    "nepochs = 200\n",
    "clamp_lower = -0.01\n",
    "clamp_upper = 0.01\n",
    "n_critic = 5\n",
    "iterate = 1000\n",
    "lrD = 0.00005\n",
    "lrG = 0.00005\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mixture_circle(batchsize, num_cluster=8, scale=1, std=1):\n",
    "\trand_indices = np.random.randint(0, num_cluster, size=batchsize)\n",
    "\tbase_angle = math.pi * 2 / num_cluster\n",
    "\tangle = rand_indices * base_angle - math.pi / 2\n",
    "\tmean = np.zeros((batchsize, 2), dtype=np.float32)\n",
    "\tmean[:, 0] = np.cos(angle) * scale\n",
    "\tmean[:, 1] = np.sin(angle) * scale\n",
    "\treturn np.random.normal(mean, std**2, (batchsize, 2)).astype(np.float32)\n",
    "\n",
    "def gaussian_mixture_double_circle(batchsize, num_cluster=8, scale=1, std=1):\n",
    "\trand_indices = np.random.randint(0, num_cluster, size=batchsize)\n",
    "\tbase_angle = math.pi * 2 / num_cluster\n",
    "\tangle = rand_indices * base_angle - math.pi / 2\n",
    "\tmean = np.zeros((batchsize, 2), dtype=np.float32)\n",
    "\tmean[:, 0] = np.cos(angle) * scale\n",
    "\tmean[:, 1] = np.sin(angle) * scale\n",
    "\t# Doubles the scale in case of even number\n",
    "\teven_indices = np.argwhere(rand_indices % 2 == 0)\n",
    "\tmean[even_indices] /= 2\n",
    "\treturn np.random.normal(mean, std**2, (batchsize, 2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kde(data, dir=None, filename=\"kde\", color=\"Greens\"):\n",
    "    fig = pylab.gcf()\n",
    "    fig.set_size_inches(4.0, 4.0)\n",
    "    pylab.clf()\n",
    "    bg_color  = sns.color_palette(color, n_colors=256)[0]\n",
    "    ax = sns.kdeplot(data[:, 0], data[:,1], shade=True, cmap=color, n_levels=30, clip=[[-4, 4]]*2)\n",
    "    ax.set_facecolor(bg_color)\n",
    "    kde = ax.get_figure()\n",
    "    pylab.xlim(-4, 4)\n",
    "    pylab.ylim(-4, 4)\n",
    "    # kde.savefig(\"{}/{}.png\".format(dir, filename))\n",
    "    pylab.show()\n",
    "\n",
    "def plot_scatter(data, dir=None, filename=\"scatter\", color=\"blue\"):\n",
    "    fig = pylab.gcf()\n",
    "    fig.set_size_inches(16.0, 16.0)\n",
    "    pylab.clf()\n",
    "    pylab.scatter(data[:, 0], data[:, 1], s=20, marker=\"o\", edgecolors=\"none\", color=color)\n",
    "    pylab.xlim(-4, 4)\n",
    "    pylab.ylim(-4, 4)\n",
    "    # pylab.savefig(\"{}/{}.png\".format(dir, filename))\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======\n",
    "# device\n",
    "# =======\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "if(cuda):\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device( \"cpu\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generator\n",
    "\n",
    "中間層のTanhの有無で結果が大きく異なる．\n",
    "\n",
    "多くは試せなかったが，Tanhなしでは分布を捉えられなかった．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz, nc):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(nz, 128),\n",
    "            nn.Tanh(),\n",
    "\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Tanh(),\n",
    "\n",
    "            nn.Linear(128, nc),\n",
    "        )\n",
    "        self.net = net\n",
    "        self.nc = nc\n",
    "        self.nz = nz\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        return output\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        net = nn.Sequential(\n",
    "            nn.Linear(nc, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "        self.net = net\n",
    "        self.nc = nc\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.net(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========\n",
    "# models\n",
    "# ==========\n",
    "generator = Generator(nz=nz, nc=nc).to(device)\n",
    "discriminator = Discriminator(nc=nc).to(device)\n",
    "\n",
    "# ==========\n",
    "# optimizer\n",
    "# ==========\n",
    "optimizer_D = optim.RMSprop(discriminator.parameters(), lr = lrD)\n",
    "optimizer_G = optim.RMSprop(generator.parameters(), lr = lrG)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if(cuda == True) and (ngpu > 1):\n",
    "    generator = nn.DataParallel(generator, list(range(ngpu)))\n",
    "    discriminator = nn.DataParallel(discriminator, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======\n",
    "# train\n",
    "# ======\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "iterations = 0\n",
    "for epoch in range(nepochs):\n",
    "    for i in range(iterate):\n",
    "        generator.train()\n",
    "        discriminator.train()\n",
    "\n",
    "        iterations += batchSize\n",
    "        \n",
    "        for param in discriminator.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        for n in range(n_critic):\n",
    "            # ====================\n",
    "            # Train the discriminator\n",
    "            # ====================\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # sample from data distribution\n",
    "            samples_ture = Variable(Tensor(gaussian_mixture_double_circle(batchsize=batchSize, num_cluster=num_mixture, scale=scale, std=std))).to(device)\n",
    "\n",
    "            # sample from generator\n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (batchSize, nz)).astype(np.float32))).to(device)\n",
    "\n",
    "            # Generate a batch of images\n",
    "            with torch.no_grad():\n",
    "                samples_fake = generator(z)\n",
    "\n",
    "            # Adversarial loss\n",
    "            real_validity = discriminator(samples_ture / scale)\n",
    "            fake_validity = discriminator(samples_fake.detach() / scale)\n",
    "\n",
    "            lossD = -torch.sum(real_validity - fake_validity) / batchSize\n",
    "            lossD.backward()\n",
    "            optimizer_D.step()\n",
    "            # Clip weights of discriminator\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(clamp_lower, clamp_upper)\n",
    "\n",
    "        # ====================\n",
    "        # Train the generator \n",
    "        # ====================\n",
    "        for param in discriminator.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (batchSize, nz)).astype(np.float32))).to(device)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        samples_fake = generator(z)\n",
    "        # Adversarial loss\n",
    "        lossG = - torch.sum(discriminator(samples_fake / scale) / batchSize)\n",
    "        lossG.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "    # ============\n",
    "    # Save images\n",
    "    # ============\n",
    "    generator.eval()\n",
    "    z_fixed = Variable(Tensor(np.random.normal(0, 1, (10000, nz)).astype(np.float32))).to(device)\n",
    "    with torch.no_grad():\n",
    "        samples_fake = generator(z_fixed)\n",
    "\n",
    "    # =====\n",
    "    # Plot\n",
    "    # =====\n",
    "    plot_scatter(samples_fake.cpu().numpy())\n",
    "    plot_kde(samples_fake.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}